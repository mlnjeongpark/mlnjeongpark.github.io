# Describe Anything

Website for the Describe Anything project.

## Describe Anything: Region-based Visual Description with Multimodal Large Language Models

**[Long Lian](https://tonylian.com)<sup>1,2</sup>, Yifan Ding<sup>1</sup>, Yunhao Ge<sup>1</sup>, Sifei Liu<sup>1</sup>, Hanzi Mao<sup>1</sup>, [Boyi Li](https://sites.google.com/site/boyilics/home)<sup>1,2</sup>, Marco Pavone<sup>1</sup>, Ming-Yu Liu<sup>1</sup>, [Trevor Darrell](https://people.eecs.berkeley.edu/~trevor/)<sup>2</sup>, [Adam Yala](https://www.adamyala.org/)<sup>2,3</sup>, Yin Cui<sup>1</sup>**

<sup>1</sup>NVIDIA &nbsp;&nbsp; <sup>2</sup>UC Berkeley &nbsp;&nbsp; <sup>3</sup>UCSF

## Overview

Our Describe Anything Model (DAM) takes in a region of an image or a video in the form of points/boxes/scribbles/masks and outputs detailed descriptions to the region. For videos, it is sufficient to supply annotation on any frame. We also release a new benchmark, DLC-Bench, to evaluate models on the Dense Local Captioning (DLC) task.

## Website Structure

- `index.html`: Main project page
- `style.css`: Styling for the website
- Various image/video assets

## Citation

If you find this work useful, please consider citing:

```
@article{lian2023describeanything,
    title={Describe Anything: Region-based Visual Description with Multimodal Large Language Models}, 
    author={Lian, Long and Ding, Yifan and Ge, Yunhao and Liu, Sifei and Mao, Hanzi and Li, Boyi and Pavone, Marco and Liu, Ming-Yu and Darrell, Trevor and Yala, Adam and Cui, Yin},
    journal={arXiv preprint},
    year={2023}
}
``` 